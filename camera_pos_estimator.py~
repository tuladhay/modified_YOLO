#!/usr/bin/env python
"""
This node will subscribe to a published video, then pass it through YOLO,
and display bounding boxed around detected cargo doors and people.

Publishers:
Subscribers:
"""

#ros specific stuff
import rospy
import roslib
from std_msgs.msg import String, Empty, Float64, Bool
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Twist
import std_srvs.srv

#tensorflow stuff
import numpy as np
from keras.models import Sequential, load_model
import tensorflow as tf

#opencv stuff
import cv2

#python stuff
import time
import sys

sys.path.append("/home/ubuntu/python_ws/driveai/")

# YOLO
import argparse
import os
import cv2
import numpy as np

from utils import draw_boxes
from frontend import YOLO
import json
import time

os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0" #"0" use cpu

class RosTensorFlow():
  def __init__(self):
    '''
      PARAMETERS AND SETTINGS
    '''
    #image size for input into NN
    self.IMAGE_WIDTH = 480
    self.IMAGE_HEIGHT = 640
    self.OUTPUT_SIZE = 1 #propel, steer

    #Where our model is stored
    self.config_path  = 'config_cargo_door.json'
    self.weights_path = '/home/ubuntu/tensorflow_data/YOLO/CargoDoor/full_yolo_cargo_door.h5'

    #what iamge topic we should use
    self.image_topic = "/tractor/camera1/image_raw"
    
    # Load config
    with open(self.config_path) as config_buffer:    
        self.config = json.load(config_buffer)
      
    self.start_time = time.time()
    self.cnt = 0

    '''
    MAKE YOLO MODEL AND LOAD TRAINED WEIGHTS
    '''
    self.yolo = YOLO(architecture        = self.config['model']['architecture'],
                input_size          = self.config['model']['input_size'], 
                labels              = self.config['model']['labels'], 
                max_box_per_image   = self.config['model']['max_box_per_image'],
                anchors             = self.config['model']['anchors'])

    print("Loading weights from: " + str(self.weights_path))
    self.yolo.load_weights(self.weights_path)
    self.model = self.yolo
    self.model._make_predict_function()
    self.graph_model = tf.get_default_graph()

    '''
      KERAS STUFF
    '''  
    #self.model = load_model(self.MODEL_STORE)
    #print("Model loaded ...")
    #self.model._make_predict_function()
    #self.graph_model = tf.get_default_graph() #must call after each model declared


    '''
      ROS STUFF
    '''
    #publish out to cmd_vel
    #self.cmd_vel_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=1)

    #setup the cv bridge
    self.bridge = CvBridge()

    #subscribe to image
    self.image_sub = rospy.Subscriber(self.image_topic, Image, self.image_callback)
    
    # timer to check subscriber is receiving images timely
    self.last_image = rospy.Time()
    self.timercb = rospy.Timer(rospy.Duration(1.0), self.timer_callback)

  def timer_callback(self, event):
    timnow = rospy.Time.from_sec(time.time())
    deltat =  timnow.to_sec() - self.last_image.to_sec()
    if(deltat > 5.0):
      print("No new video for " + str(deltat) + " seconds")
      steering_est = 0.0

  def image_callback(self, im_msg):
    self.last_image = rospy.Time.from_sec(time.time())
    
    cv_image = self.bridge.imgmsg_to_cv2(im_msg, "bgr8")
    height, width, channels = cv_image.shape

    #preprocess (BGR2YUV, crop, resize)
    #cv_image = np.array([cv_image])       # the model expects 4D array

    #pass it through YOLO
    with self.graph_model.as_default():
        boxes = self.yolo.predict(cv_image)

    #overlay boxes
    cv_image = draw_boxes(cv_image, boxes, self.config['model']['labels'])

    #display frame
    cv2.imshow("Detection", cv_image)
    cv2.waitKey(3)

  def main(self):
      #just let ros do its thing
      rospy.spin()


if __name__ == '__main__':
  cv2.startWindowThread() #to make sure we can close it later on
  print("Running driveai_node")
  #initialize ros node
  rospy.init_node('driveai_node', anonymous=True)
  #initialize our class
  rtf = RosTensorFlow()
  #run our main
  rtf.main()

